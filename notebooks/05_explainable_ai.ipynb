{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd0d NEXUS AI - Explainable AI (XAI) for AML Detection\n\n",
    "**Objective:** Provide transparent, interpretable explanations for ML predictions ensuring regulatory compliance.\n\n",
    "**Why XAI is Critical:**\n",
    "- \u2705 **GDPR Article 22** - Right to explanation\n",
    "- \u2705 **Regulatory Audits** - Justify decisions to FinCEN/FATF\n",
    "- \u2705 **Trust & Transparency** - Help analysts understand WHY\n",
    "- \u2705 **Model Debugging** - Identify biases and errors\n",
    "- \u2705 **Feature Discovery** - Find what matters most\n\n",
    "**Contents:**\n",
    "1. Setup & Data Loading\n",
    "2. Train Baseline Model\n",
    "3. SHAP (SHapley Additive exPlanations)\n",
    "4. LIME (Local Interpretable Model-agnostic Explanations)\n",
    "5. Feature Importance Analysis\n",
    "6. Individual Prediction Explanations\n",
    "7. Counterfactual Explanations\n",
    "8. Global Model Behavior\n",
    "9. Compliance Reporting\n",
    "10. Production Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n\n",
    "# XAI libraries\n",
    "try:\n",
    "    import shap\n",
    "    print('\u2705 SHAP loaded')\n",
    "    SHAP_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print('\u274c SHAP not available - install: pip install shap')\n",
    "    SHAP_AVAILABLE = False\n\n",
    "try:\n",
    "    import lime\n",
    "    import lime.lime_tabular\n",
    "    print('\u2705 LIME loaded')\n",
    "    LIME_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print('\u274c LIME not available - install: pip install lime')\n",
    "    LIME_AVAILABLE = False\n\n",
    "try:\n",
    "    import xgboost as xgb\n",
    "    print('\u2705 XGBoost loaded')\n",
    "except ImportError:\n",
    "    print('\u274c XGBoost not available')\n\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "np.random.seed(42)\n\n",
    "print('\\n\ud83d\udd0d NEXUS AI - Explainable AI Module Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Data Loading & Model Training\n\nLoad AML transaction data and train a model to explain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic AML data\n",
    "n_samples = 2000\n",
    "n_features = 30\n\n",
    "np.random.seed(42)\n",
    "X = np.random.randn(n_samples, n_features)\n",
    "y = np.zeros(n_samples)\n",
    "n_suspicious = int(n_samples * 0.05)\n",
    "suspicious_indices = np.random.choice(n_samples, n_suspicious, replace=False)\n",
    "y[suspicious_indices] = 1\n\n",
    "# Make suspicious transactions distinguishable\n",
    "X[suspicious_indices, :10] += 2.5\n",
    "X[suspicious_indices, 10:20] -= 2.0\n\n",
    "# Feature names\n",
    "feature_names = [\n",
    "    'amount_log', 'amount_zscore', 'hour_of_day', 'day_of_week', 'is_weekend',\n",
    "    'velocity_7d', 'velocity_30d', 'frequency_7d', 'frequency_30d', 'frequency_change',\n",
    "    'cross_border', 'high_risk_country', 'round_amount', 'cash_intensive', 'crypto_related',\n",
    "    'customer_age_days', 'avg_amount_7d', 'avg_amount_30d', 'std_amount_7d', 'std_amount_30d',\n",
    "    'betweenness_centrality', 'degree_centrality', 'clustering_coef', 'pagerank',\n",
    "    'time_since_last', 'burst_indicator', 'structuring_indicator', 'layering_score',\n",
    "    'sanctions_proximity', 'pep_indicator'\n",
    "]\n\n",
    "df = pd.DataFrame(X, columns=feature_names)\n",
    "df['target'] = y\n\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n",
    "# Scale\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n\n",
    "print(f'\ud83d\udcca Data: {n_samples:,} samples, {n_features} features')\n",
    "print(f'\ud83d\udea8 Suspicious: {y.sum():.0f} ({y.mean()*100:.1f}%)')\n",
    "print(f'\u2705 Train: {len(X_train)}, Test: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train XGBoost model\n",
    "model = xgb.XGBClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    learning_rate=0.1,\n",
    "    scale_pos_weight=19,  # Class imbalance\n",
    "    random_state=42,\n",
    "    use_label_encoder=False,\n",
    "    eval_metric='logloss'\n",
    ")\n\n",
    "print('\ud83d\ude80 Training XGBoost...')\n",
    "model.fit(X_train_scaled, y_train)\n\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "y_proba = model.predict_proba(X_test_scaled)[:, 1]\n\n",
    "print(f'\\n\ud83d\udcca Model Performance:')\n",
    "print(f'   Accuracy: {accuracy_score(y_test, y_pred):.4f}')\n",
    "print(f'   ROC-AUC: {roc_auc_score(y_test, y_proba):.4f}')\n",
    "print('\\n\u2705 Model ready for explanation!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 SHAP (SHapley Additive exPlanations)\n\n",
    "**SHAP** provides game-theory based feature attributions.\n\n",
    "**Key Concepts:**\n",
    "- **Shapley values**: Fair contribution of each feature\n",
    "- **Additive**: Sum of SHAP values = prediction - baseline\n",
    "- **Consistent**: More contribution = higher SHAP value\n",
    "- **Local accuracy**: Accurate individual explanations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE:\n",
    "    print('\ud83d\udd0d Computing SHAP values...')\n",
    "    print('   (This may take 1-2 minutes...)\\n')\n",
    "    \n",
    "    # Create explainer\n",
    "    explainer = shap.TreeExplainer(model)\n",
    "    \n",
    "    # Compute SHAP values\n",
    "    shap_values = explainer.shap_values(X_test_scaled)\n",
    "    \n",
    "    # Handle binary classification\n",
    "    if isinstance(shap_values, list):\n",
    "        shap_values = shap_values[1]  # Positive class\n",
    "    \n",
    "    print(f'\u2705 SHAP values computed: {shap_values.shape}')\n",
    "    print(f'   Base value (expected output): {explainer.expected_value:.4f}')\n",
    "    print(f'   Mean |SHAP|: {np.abs(shap_values).mean():.4f}')\n",
    "else:\n",
    "    print('\u26a0\ufe0f  SHAP not available')\n",
    "    print('   Install: pip install shap')\n",
    "    shap_values = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 SHAP Summary Plot - Global Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and shap_values is not None:\n",
    "    plt.figure(figsize=(12, 10))\n",
    "    shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names, show=False)\n",
    "    plt.title('\ud83c\udfaf SHAP Feature Importance Summary', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print('\\n\ud83d\udcca How to interpret:')\n",
    "    print('   \u2022 Top features = most important globally')\n",
    "    print('   \u2022 Red = high feature value, Blue = low value')\n",
    "    print('   \u2022 Right = increases suspicion, Left = decreases')\n",
    "    print('   \u2022 Width = distribution of impact')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SHAP Bar Plot - Mean Absolute Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and shap_values is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names, \n",
    "                     plot_type='bar', show=False)\n",
    "    plt.title('\ud83d\udcca Mean Absolute SHAP Values', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Top 10\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    top_10 = np.argsort(mean_abs_shap)[-10:][::-1]\n",
    "    \n",
    "    print('\\n\ud83c\udfc6 TOP 10 FEATURES BY IMPACT:')\n",
    "    print('=' * 60)\n",
    "    for i, idx in enumerate(top_10, 1):\n",
    "        print(f'{i:2d}. {feature_names[idx]:30s} | {mean_abs_shap[idx]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Individual Prediction - Suspicious Transaction Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and shap_values is not None:\n",
    "    # Find suspicious transaction\n",
    "    susp_idx = np.where(y_test == 1)[0]\n",
    "    if len(susp_idx) > 0:\n",
    "        idx = susp_idx[0]\n",
    "        \n",
    "        print(f'\ud83d\udd0d Explaining Transaction #{idx}')\n",
    "        print('=' * 70)\n",
    "        print(f'True Label: SUSPICIOUS')\n",
    "        print(f'Predicted: {\"SUSPICIOUS\" if y_pred[idx]==1 else \"NORMAL\"}')\n",
    "        print(f'Probability: {y_proba[idx]:.2%}\\n')\n",
    "        \n",
    "        # Waterfall\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        shap.waterfall_plot(\n",
    "            shap.Explanation(\n",
    "                values=shap_values[idx],\n",
    "                base_values=explainer.expected_value,\n",
    "                data=X_test_scaled[idx],\n",
    "                feature_names=feature_names\n",
    "            ),\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f'\ud83d\udca7 Feature Contributions (Transaction #{idx})', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Top contributors\n",
    "        contribs = list(zip(feature_names, shap_values[idx], X_test_scaled[idx]))\n",
    "        contribs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        print('\\n\ud83d\udccb TOP 10 CONTRIBUTORS:')\n",
    "        for i, (name, shap_val, feat_val) in enumerate(contribs[:10], 1):\n",
    "            dir = '\u2191' if shap_val > 0 else '\u2193'\n",
    "            print(f'{i:2d}. {name:30s} {dir} | SHAP: {shap_val:+.4f} | Val: {feat_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 LIME (Local Interpretable Model-agnostic Explanations)\n\nLIME approximates the model locally with an interpretable linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIME_AVAILABLE:\n",
    "    print('\ud83c\udf4b Creating LIME explainer...\\n')\n",
    "    \n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train_scaled,\n",
    "        feature_names=feature_names,\n",
    "        class_names=['Normal', 'Suspicious'],\n",
    "        mode='classification',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print('\u2705 LIME explainer ready')\n",
    "else:\n",
    "    print('\u26a0\ufe0f  LIME not available - install: pip install lime')\n",
    "    lime_explainer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LIME Explanation for Same Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIME_AVAILABLE and lime_explainer and len(susp_idx) > 0:\n",
    "    print(f'\ud83c\udf4b Generating LIME explanation for Transaction #{idx}...\\n')\n",
    "    \n",
    "    lime_exp = lime_explainer.explain_instance(\n",
    "        X_test_scaled[idx],\n",
    "        model.predict_proba,\n",
    "        num_features=10,\n",
    "        top_labels=1\n",
    "    )\n",
    "    \n",
    "    # Visualize\n",
    "    fig = lime_exp.as_pyplot_figure(label=1)\n",
    "    plt.title(f'\ud83c\udf4b LIME Explanation (Transaction #{idx})', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Details\n",
    "    print('\\n\ud83d\udccb LIME Feature Weights:')\n",
    "    print('=' * 70)\n",
    "    for feature, weight in lime_exp.as_list(label=1):\n",
    "        dir = '\u2191' if weight > 0 else '\u2193'\n",
    "        print(f'{feature:50s} {dir} | {weight:+.4f}')\n",
    "    \n",
    "    print(f'\\n\ud83c\udfaf LIME prediction: {lime_exp.local_pred[0]:.4f}')\n",
    "    print(f'\ud83c\udfaf True prediction: {y_proba[idx]:.4f}')\n",
    "    print(f'\u2705 Difference: {abs(lime_exp.local_pred[0] - y_proba[idx]):.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 SHAP Bar Plot - Mean Absolute Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and shap_values is not None:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    shap.summary_plot(shap_values, X_test_scaled, feature_names=feature_names, \n",
    "                     plot_type='bar', show=False)\n",
    "    plt.title('\ud83d\udcca Mean Absolute SHAP Values', fontsize=16, fontweight='bold', pad=20)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Top 10\n",
    "    mean_abs_shap = np.abs(shap_values).mean(axis=0)\n",
    "    top_10 = np.argsort(mean_abs_shap)[-10:][::-1]\n",
    "    \n",
    "    print('\\n\ud83c\udfc6 TOP 10 FEATURES BY IMPACT:')\n",
    "    print('=' * 60)\n",
    "    for i, idx in enumerate(top_10, 1):\n",
    "        print(f'{i:2d}. {feature_names[idx]:30s} | {mean_abs_shap[idx]:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Individual Prediction - Suspicious Transaction Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if SHAP_AVAILABLE and shap_values is not None:\n",
    "    # Find suspicious transaction\n",
    "    susp_idx = np.where(y_test == 1)[0]\n",
    "    if len(susp_idx) > 0:\n",
    "        idx = susp_idx[0]\n",
    "        \n",
    "        print(f'\ud83d\udd0d Explaining Transaction #{idx}')\n",
    "        print('=' * 70)\n",
    "        print(f'True Label: SUSPICIOUS')\n",
    "        print(f'Predicted: {\"SUSPICIOUS\" if y_pred[idx]==1 else \"NORMAL\"}')\n",
    "        print(f'Probability: {y_proba[idx]:.2%}\\n')\n",
    "        \n",
    "        # Waterfall\n",
    "        plt.figure(figsize=(14, 8))\n",
    "        shap.waterfall_plot(\n",
    "            shap.Explanation(\n",
    "                values=shap_values[idx],\n",
    "                base_values=explainer.expected_value,\n",
    "                data=X_test_scaled[idx],\n",
    "                feature_names=feature_names\n",
    "            ),\n",
    "            show=False\n",
    "        )\n",
    "        plt.title(f'\ud83d\udca7 Feature Contributions (Transaction #{idx})', fontsize=14, fontweight='bold')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        # Top contributors\n",
    "        contribs = list(zip(feature_names, shap_values[idx], X_test_scaled[idx]))\n",
    "        contribs.sort(key=lambda x: abs(x[1]), reverse=True)\n",
    "        \n",
    "        print('\\n\ud83d\udccb TOP 10 CONTRIBUTORS:')\n",
    "        for i, (name, shap_val, feat_val) in enumerate(contribs[:10], 1):\n",
    "            dir = '\u2191' if shap_val > 0 else '\u2193'\n",
    "            print(f'{i:2d}. {name:30s} {dir} | SHAP: {shap_val:+.4f} | Val: {feat_val:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 LIME (Local Interpretable Model-agnostic Explanations)\n\nLIME approximates the model locally with an interpretable linear model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIME_AVAILABLE:\n",
    "    print('\ud83c\udf4b Creating LIME explainer...\\n')\n",
    "    \n",
    "    lime_explainer = lime.lime_tabular.LimeTabularExplainer(\n",
    "        X_train_scaled,\n",
    "        feature_names=feature_names,\n",
    "        class_names=['Normal', 'Suspicious'],\n",
    "        mode='classification',\n",
    "        random_state=42\n",
    "    )\n",
    "    \n",
    "    print('\u2705 LIME explainer ready')\n",
    "else:\n",
    "    print('\u26a0\ufe0f  LIME not available - install: pip install lime')\n",
    "    lime_explainer = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LIME Explanation for Same Transaction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if LIME_AVAILABLE and lime_explainer and len(susp_idx) > 0:\n",
    "    print(f'\ud83c\udf4b Generating LIME explanation for Transaction #{idx}...\\n')\n",
    "    \n",
    "    lime_exp = lime_explainer.explain_instance(\n",
    "        X_test_scaled[idx],\n",
    "        model.predict_proba,\n",
    "        num_features=10,\n",
    "        top_labels=1\n",
    "    )\n",
    "    \n",
    "    # Visualize\n",
    "    fig = lime_exp.as_pyplot_figure(label=1)\n",
    "    plt.title(f'\ud83c\udf4b LIME Explanation (Transaction #{idx})', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Details\n",
    "    print('\\n\ud83d\udccb LIME Feature Weights:')\n",
    "    print('=' * 70)\n",
    "    for feature, weight in lime_exp.as_list(label=1):\n",
    "        dir = '\u2191' if weight > 0 else '\u2193'\n",
    "        print(f'{feature:50s} {dir} | {weight:+.4f}')\n",
    "    \n",
    "    print(f'\\n\ud83c\udfaf LIME prediction: {lime_exp.local_pred[0]:.4f}')\n",
    "    print(f'\ud83c\udfaf True prediction: {y_proba[idx]:.4f}')\n",
    "    print(f'\u2705 Difference: {abs(lime_exp.local_pred[0] - y_proba[idx]):.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}