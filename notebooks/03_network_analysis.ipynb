{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83d\udd78\ufe0f NEXUS AI - Network Graph Analysis\\n\\n**Objective:** Analyze transaction networks to identify money laundering rings and complex schemes.\\n\\n**Contents:**\\n1. Network Construction\\n2. Community Detection\\n3. Centrality Analysis\\n4. Suspicious Pattern Detection\\n5. Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Imports",
    "import pandas as pd",
    "import numpy as np",
    "import matplotlib.pyplot as plt",
    "import networkx as nx",
    "from collections import Counter",
    "import warnings",
    "warnings.filterwarnings('ignore')",
    "",
    "print(\"\u2705 Network analysis libraries loaded\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Network Construction\\n\\nBuild transaction network from sender-receiver relationships."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Generate synthetic transaction network",
    "np.random.seed(42)",
    "n_nodes = 100",
    "n_transactions = 500",
    "",
    "# Create transaction edges",
    "edges = []",
    "amounts = []",
    "for _ in range(n_transactions):",
    "    sender = f\"CUST-{np.random.randint(1, n_nodes):03d}\"",
    "    receiver = f\"CUST-{np.random.randint(1, n_nodes):03d}\"",
    "    if sender != receiver:",
    "        edges.append((sender, receiver))",
    "        amounts.append(np.random.lognormal(9, 1))",
    "",
    "# Create graph",
    "G = nx.DiGraph()",
    "for (sender, receiver), amount in zip(edges, amounts):",
    "    if G.has_edge(sender, receiver):",
    "        G[sender][receiver]['weight'] += amount",
    "        G[sender][receiver]['count'] += 1",
    "    else:",
    "        G.add_edge(sender, receiver, weight=amount, count=1)",
    "",
    "print(f\"\ud83d\udd78\ufe0f Network created:\")",
    "print(f\"   Nodes: {G.number_of_nodes()}\")",
    "print(f\"   Edges: {G.number_of_edges()}\")",
    "print(f\"   Density: {nx.density(G):.4f}\")",
    "print(f\"   Connected: {nx.is_weakly_connected(G)}\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 Community Detection\\n\\nIdentify clusters of closely connected accounts (potential layering schemes)."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "from networkx.algorithms import community",
    "",
    "# Convert to undirected for community detection",
    "G_undirected = G.to_undirected()",
    "",
    "# Louvain community detection",
    "communities = community.louvain_communities(G_undirected, seed=42)",
    "",
    "print(f\"\ud83d\udc65 Communities detected: {len(communities)}\")",
    "for i, comm in enumerate(communities[:5]):",
    "    print(f\"   Community {i+1}: {len(comm)} members\")",
    "",
    "# Assign community labels",
    "community_map = {}",
    "for i, comm in enumerate(communities):",
    "    for node in comm:",
    "        community_map[node] = i",
    "",
    "nx.set_node_attributes(G, community_map, 'community')"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 Centrality Analysis\\n\\nIdentify key players in the network using multiple centrality metrics."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Calculate centrality metrics",
    "degree_cent = nx.degree_centrality(G)",
    "betweenness_cent = nx.betweenness_centrality(G)",
    "closeness_cent = nx.closeness_centrality(G)",
    "pagerank = nx.pagerank(G)",
    "",
    "# Combine into DataFrame",
    "centrality_df = pd.DataFrame({",
    "    'degree': degree_cent,",
    "    'betweenness': betweenness_cent,",
    "    'closeness': closeness_cent,",
    "    'pagerank': pagerank",
    "})",
    "",
    "# Calculate risk score",
    "centrality_df['risk_score'] = (",
    "    centrality_df['degree'] * 0.3 +",
    "    centrality_df['betweenness'] * 0.4 +",
    "    centrality_df['pagerank'] * 0.3",
    ")",
    "",
    "print(\"\ud83c\udfaf Top 10 High-Risk Nodes (by risk score):\")",
    "print(centrality_df.nlargest(10, 'risk_score'))"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Suspicious Pattern Detection\\n\\nIdentify specific AML patterns: rapid movement, circular flows, layering."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Detect circular flows (potential layering)",
    "cycles = list(nx.simple_cycles(G))",
    "print(f\"\ud83d\udd04 Circular flows detected: {len(cycles)}\")",
    "",
    "# Detect high-velocity nodes",
    "high_velocity = centrality_df[centrality_df['degree'] > centrality_df['degree'].quantile(0.90)]",
    "print(f\"\u26a1 High-velocity nodes: {len(high_velocity)}\")",
    "",
    "# Detect hub-and-spoke patterns",
    "out_degree = dict(G.out_degree())",
    "in_degree = dict(G.in_degree())",
    "hubs = [node for node, deg in out_degree.items() if deg > 10]",
    "print(f\"\ud83c\udfaf Hub nodes detected: {len(hubs)}\")",
    "",
    "print(\"\\n\u26a0\ufe0f SUSPICIOUS PATTERNS:\")",
    "for hub in hubs[:5]:",
    "    print(f\"   {hub}: {out_degree[hub]} outgoing, {in_degree[hub]} incoming\")"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\ufe0f\u20e3 Network Visualization"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))",
    "",
    "# Layout",
    "pos = nx.spring_layout(G, k=0.5, iterations=50, seed=42)",
    "",
    "# 1. Community visualization",
    "node_colors = [community_map[node] for node in G.nodes()]",
    "nx.draw_networkx(G, pos, node_color=node_colors, cmap='Set3', ",
    "                 node_size=100, with_labels=False, ",
    "                 edge_color='gray', alpha=0.6, ax=axes[0])",
    "axes[0].set_title('\ud83d\udc65 Network Communities', fontsize=14, fontweight='bold')",
    "axes[0].axis('off')",
    "",
    "# 2. Risk score visualization",
    "node_sizes = [centrality_df.loc[node, 'risk_score'] * 1000 for node in G.nodes()]",
    "node_colors_risk = [centrality_df.loc[node, 'risk_score'] for node in G.nodes()]",
    "nx.draw_networkx(G, pos, node_color=node_colors_risk, cmap='YlOrRd',",
    "                 node_size=node_sizes, with_labels=False,",
    "                 edge_color='gray', alpha=0.6, ax=axes[1])",
    "axes[1].set_title('\ud83d\udea8 Risk Score (size & color)', fontsize=14, fontweight='bold')",
    "axes[1].axis('off')",
    "",
    "plt.tight_layout()",
    "plt.show()",
    "",
    "print(\"\\n\u2705 Network analysis complete!\")"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}