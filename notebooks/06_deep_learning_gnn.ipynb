{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \ud83e\udde0 NEXUS AI - Deep Learning & Graph Neural Networks\n\n",
    "**Objective:** Advanced deep learning for AML detection using GNNs and LSTMs.\n\n",
    "**Why Deep Learning:**\n",
    "- \u2705 Captures complex non-linear patterns\n",
    "- \u2705 Learns hierarchical representations\n",
    "- \u2705 GNNs excel at network-based detection\n",
    "- \u2705 LSTMs capture temporal sequences\n",
    "- \u2705 Attention mechanisms highlight important features\n\n",
    "**Contents:**\n",
    "1. Setup & Data Preparation\n",
    "2. Graph Neural Network (GNN) for Network Analysis\n",
    "3. LSTM for Transaction Sequences\n",
    "4. Transformer-based Anomaly Detection\n",
    "5. Model Comparison\n",
    "6. Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n\n",
    "# Deep Learning\n",
    "try:\n",
    "    import torch\n",
    "    import torch.nn as nn\n",
    "    import torch.nn.functional as F\n",
    "    from torch.utils.data import Dataset, DataLoader\n",
    "    print('\u2705 PyTorch loaded')\n",
    "    TORCH_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print('\u274c PyTorch not available - install: pip install torch')\n",
    "    TORCH_AVAILABLE = False\n\n",
    "try:\n",
    "    import torch_geometric\n",
    "    from torch_geometric.nn import GCNConv, GATConv, SAGEConv\n",
    "    from torch_geometric.data import Data\n",
    "    print('\u2705 PyTorch Geometric loaded')\n",
    "    TORCH_GEO_AVAILABLE = True\n",
    "except ImportError:\n",
    "    print('\u274c PyTorch Geometric not available - install: pip install torch-geometric')\n",
    "    TORCH_GEO_AVAILABLE = False\n\n",
    "sns.set_style('darkgrid')\n",
    "plt.rcParams['figure.figsize'] = (14, 8)\n",
    "np.random.seed(42)\n",
    "if TORCH_AVAILABLE:\n",
    "    torch.manual_seed(42)\n\n",
    "print('\\n\ud83e\udde0 Deep Learning Module Initialized')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1\ufe0f\u20e3 Data Preparation\n\nPrepare transaction network data for GNN training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate network data\n",
    "np.random.seed(42)\n",
    "n_nodes = 200\n",
    "n_edges = 500\n\n",
    "# Create edges (transactions)\n",
    "edges = []\n",
    "for _ in range(n_edges):\n",
    "    src = np.random.randint(0, n_nodes)\n",
    "    dst = np.random.randint(0, n_nodes)\n",
    "    if src != dst:\n",
    "        edges.append([src, dst])\n\n",
    "edges = np.array(edges).T\n\n",
    "# Node features (customer profiles)\n",
    "node_features = np.random.randn(n_nodes, 16)\n\n",
    "# Labels (5% suspicious)\n",
    "node_labels = np.zeros(n_nodes)\n",
    "susp_nodes = np.random.choice(n_nodes, int(n_nodes * 0.05), replace=False)\n",
    "node_labels[susp_nodes] = 1\n\n",
    "# Make suspicious nodes more extreme\n",
    "node_features[susp_nodes] += 2\n\n",
    "print(f'\ud83d\udd78\ufe0f Network Data:')\n",
    "print(f'   Nodes: {n_nodes}')\n",
    "print(f'   Edges: {len(edges[0])}')\n",
    "print(f'   Suspicious: {node_labels.sum():.0f} ({node_labels.mean()*100:.1f}%)')\n",
    "print(f'   Features per node: {node_features.shape[1]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2\ufe0f\u20e3 Graph Neural Network (GNN)\n\nGNN propagates information through the network to detect suspicious clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE and TORCH_GEO_AVAILABLE:\n",
    "    # Define GNN model\n",
    "    class GNNDetector(nn.Module):\n",
    "        def __init__(self, in_features, hidden_dim=64, num_classes=2):\n",
    "            super().__init__()\n",
    "            self.conv1 = GCNConv(in_features, hidden_dim)\n",
    "            self.conv2 = GCNConv(hidden_dim, hidden_dim)\n",
    "            self.conv3 = GCNConv(hidden_dim, hidden_dim // 2)\n",
    "            self.fc = nn.Linear(hidden_dim // 2, num_classes)\n",
    "            self.dropout = nn.Dropout(0.3)\n",
    "        \n",
    "        def forward(self, x, edge_index):\n",
    "            x = self.conv1(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "            x = self.conv2(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            x = self.dropout(x)\n",
    "            \n",
    "            x = self.conv3(x, edge_index)\n",
    "            x = F.relu(x)\n",
    "            \n",
    "            x = self.fc(x)\n",
    "            return F.log_softmax(x, dim=1)\n",
    "    \n",
    "    # Create PyG Data object\n",
    "    data = Data(\n",
    "        x=torch.FloatTensor(node_features),\n",
    "        edge_index=torch.LongTensor(edges),\n",
    "        y=torch.LongTensor(node_labels)\n",
    "    )\n",
    "    \n",
    "    # Split\n",
    "    n_train = int(n_nodes * 0.7)\n",
    "    n_val = int(n_nodes * 0.15)\n",
    "    \n",
    "    indices = torch.randperm(n_nodes)\n",
    "    train_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "    val_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "    test_mask = torch.zeros(n_nodes, dtype=torch.bool)\n",
    "    \n",
    "    train_mask[indices[:n_train]] = True\n",
    "    val_mask[indices[n_train:n_train+n_val]] = True\n",
    "    test_mask[indices[n_train+n_val:]] = True\n",
    "    \n",
    "    data.train_mask = train_mask\n",
    "    data.val_mask = val_mask\n",
    "    data.test_mask = test_mask\n",
    "    \n",
    "    print('\u2705 GNN data prepared')\n",
    "    print(f'   Train: {train_mask.sum()}, Val: {val_mask.sum()}, Test: {test_mask.sum()}')\n",
    "else:\n",
    "    print('\u26a0\ufe0f  PyTorch Geometric not available')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Train GNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE and TORCH_GEO_AVAILABLE:\n",
    "    # Initialize\n",
    "    model_gnn = GNNDetector(in_features=16, hidden_dim=64)\n",
    "    optimizer = torch.optim.Adam(model_gnn.parameters(), lr=0.01, weight_decay=5e-4)\n",
    "    criterion = nn.NLLLoss()\n",
    "    \n",
    "    # Training\n",
    "    print('\ud83d\ude80 Training GNN (50 epochs)...\\n')\n",
    "    model_gnn.train()\n",
    "    \n",
    "    for epoch in range(50):\n",
    "        optimizer.zero_grad()\n",
    "        out = model_gnn(data.x, data.edge_index)\n",
    "        loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            model_gnn.eval()\n",
    "            with torch.no_grad():\n",
    "                pred = model_gnn(data.x, data.edge_index).argmax(dim=1)\n",
    "                train_acc = (pred[data.train_mask] == data.y[data.train_mask]).float().mean()\n",
    "                val_acc = (pred[data.val_mask] == data.y[data.val_mask]).float().mean()\n",
    "            model_gnn.train()\n",
    "            print(f'Epoch {epoch+1:3d} | Loss: {loss:.4f} | Train: {train_acc:.4f} | Val: {val_acc:.4f}')\n",
    "    \n",
    "    # Final evaluation\n",
    "    model_gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        pred = model_gnn(data.x, data.edge_index).argmax(dim=1)\n",
    "        test_acc = (pred[data.test_mask] == data.y[data.test_mask]).float().mean()\n",
    "    \n",
    "    print(f'\\n\u2705 GNN Training Complete!')\n",
    "    print(f'   Test Accuracy: {test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Visualize GNN Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE and TORCH_GEO_AVAILABLE:\n",
    "    from sklearn.decomposition import PCA\n",
    "    \n",
    "    model_gnn.eval()\n",
    "    with torch.no_grad():\n",
    "        x = model_gnn.conv1(data.x, data.edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = model_gnn.conv2(x, data.edge_index)\n",
    "        embeddings = x.numpy()\n",
    "    \n",
    "    pca = PCA(n_components=2)\n",
    "    emb_2d = pca.fit_transform(embeddings)\n",
    "    \n",
    "    plt.figure(figsize=(14, 10))\n",
    "    colors = ['blue' if l == 0 else 'red' for l in data.y.numpy()]\n",
    "    plt.scatter(emb_2d[:, 0], emb_2d[:, 1], c=colors, alpha=0.6, s=100)\n",
    "    plt.title('\ud83e\udde0 GNN Node Embeddings (2D PCA)', fontsize=16, fontweight='bold')\n",
    "    plt.xlabel('PC1')\n",
    "    plt.ylabel('PC2')\n",
    "    plt.legend(['Normal', 'Suspicious'], loc='best')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3\ufe0f\u20e3 LSTM for Transaction Sequences\n\nLSTMs capture temporal patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    n_customers = 500\n",
    "    seq_length = 20\n",
    "    n_seq_features = 10\n",
    "    \n",
    "    sequences = np.random.randn(n_customers, seq_length, n_seq_features)\n",
    "    seq_labels = np.zeros(n_customers)\n",
    "    \n",
    "    susp_cust = np.random.choice(n_customers, int(n_customers * 0.05), replace=False)\n",
    "    seq_labels[susp_cust] = 1\n",
    "    \n",
    "    for idx in susp_cust:\n",
    "        sequences[idx, :, 0] = np.linspace(0, 3, seq_length)\n",
    "        sequences[idx, 15:, 1] += 3\n",
    "    \n",
    "    class SequenceDataset(Dataset):\n",
    "        def __init__(self, sequences, labels):\n",
    "            self.sequences = torch.FloatTensor(sequences)\n",
    "            self.labels = torch.LongTensor(labels)\n",
    "        def __len__(self):\n",
    "            return len(self.sequences)\n",
    "        def __getitem__(self, idx):\n",
    "            return self.sequences[idx], self.labels[idx]\n",
    "    \n",
    "    train_size = int(n_customers * 0.7)\n",
    "    val_size = int(n_customers * 0.15)\n",
    "    \n",
    "    train_data = SequenceDataset(sequences[:train_size], seq_labels[:train_size])\n",
    "    val_data = SequenceDataset(sequences[train_size:train_size+val_size], seq_labels[train_size:train_size+val_size])\n",
    "    test_data = SequenceDataset(sequences[train_size+val_size:], seq_labels[train_size+val_size:])\n",
    "    \n",
    "    train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "    val_loader = DataLoader(val_data, batch_size=32)\n",
    "    test_loader = DataLoader(test_data, batch_size=32)\n",
    "    \n",
    "    print(f'\ud83d\udcca Sequences: {n_customers}, Length: {seq_length}, Features: {n_seq_features}')\n",
    "    print(f'\ud83d\udea8 Suspicious: {seq_labels.sum():.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    class LSTMDetector(nn.Module):\n",
    "        def __init__(self, input_dim, hidden_dim=128, num_layers=2, num_classes=2):\n",
    "            super().__init__()\n",
    "            self.lstm = nn.LSTM(input_dim, hidden_dim, num_layers, batch_first=True, dropout=0.3)\n",
    "            self.attention = nn.Linear(hidden_dim, 1)\n",
    "            self.fc = nn.Sequential(\n",
    "                nn.Linear(hidden_dim, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Dropout(0.3),\n",
    "                nn.Linear(64, num_classes)\n",
    "            )\n",
    "        def forward(self, x):\n",
    "            lstm_out, _ = self.lstm(x)\n",
    "            attn_weights = torch.softmax(self.attention(lstm_out), dim=1)\n",
    "            context = torch.sum(attn_weights * lstm_out, dim=1)\n",
    "            out = self.fc(context)\n",
    "            return F.log_softmax(out, dim=1)\n",
    "    \n",
    "    model_lstm = LSTMDetector(input_dim=n_seq_features)\n",
    "    print('\u2705 LSTM with attention defined')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Train LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    optimizer_lstm = torch.optim.Adam(model_lstm.parameters(), lr=0.001)\n",
    "    criterion_lstm = nn.NLLLoss()\n",
    "    \n",
    "    print('\ud83d\ude80 Training LSTM (30 epochs)...\\n')\n",
    "    history = {'train_loss': [], 'val_loss': [], 'train_acc': [], 'val_acc': []}\n",
    "    \n",
    "    for epoch in range(30):\n",
    "        model_lstm.train()\n",
    "        train_loss = train_correct = train_total = 0\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer_lstm.zero_grad()\n",
    "            outputs = model_lstm(seqs)\n",
    "            loss = criterion_lstm(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer_lstm.step()\n",
    "            train_loss += loss.item()\n",
    "            train_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "            train_total += labels.size(0)\n",
    "        \n",
    "        model_lstm.eval()\n",
    "        val_loss = val_correct = val_total = 0\n",
    "        with torch.no_grad():\n",
    "            for seqs, labels in val_loader:\n",
    "                outputs = model_lstm(seqs)\n",
    "                val_loss += criterion_lstm(outputs, labels).item()\n",
    "                val_correct += (outputs.argmax(dim=1) == labels).sum().item()\n",
    "                val_total += labels.size(0)\n",
    "        \n",
    "        history['train_loss'].append(train_loss / len(train_loader))\n",
    "        history['val_loss'].append(val_loss / len(val_loader))\n",
    "        history['train_acc'].append(train_correct / train_total)\n",
    "        history['val_acc'].append(val_correct / val_total)\n",
    "        \n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch+1:2d} | Loss: {history[\"train_loss\"][-1]:.4f} | Acc: {history[\"train_acc\"][-1]:.4f}')\n",
    "    \n",
    "    model_lstm.eval()\n",
    "    test_correct = test_total = 0\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in test_loader:\n",
    "            test_correct += (model_lstm(seqs).argmax(dim=1) == labels).sum().item()\n",
    "            test_total += labels.size(0)\n",
    "    lstm_test_acc = test_correct / test_total\n",
    "    print(f'\\n\u2705 LSTM Test Accuracy: {lstm_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    ax1.plot(history['train_loss'], label='Train', linewidth=2)\n",
    "    ax1.plot(history['val_loss'], label='Val', linewidth=2)\n",
    "    ax1.set_title('\ud83d\udcc9 Loss', fontsize=14, fontweight='bold')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax2.plot(history['train_acc'], label='Train', linewidth=2)\n",
    "    ax2.plot(history['val_acc'], label='Val', linewidth=2)\n",
    "    ax2.set_title('\ud83d\udcc8 Accuracy', fontsize=14, fontweight='bold')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4\ufe0f\u20e3 Transformer Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    class TransformerDetector(nn.Module):\n",
    "        def __init__(self, input_dim, d_model=64, nhead=4, num_layers=3):\n",
    "            super().__init__()\n",
    "            self.input_proj = nn.Linear(input_dim, d_model)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model, nhead, 256, 0.1, batch_first=True)\n",
    "            self.transformer = nn.TransformerEncoder(encoder_layer, num_layers)\n",
    "            self.fc = nn.Sequential(nn.Linear(d_model, 32), nn.ReLU(), nn.Dropout(0.2), nn.Linear(32, 2))\n",
    "        def forward(self, x):\n",
    "            x = self.input_proj(x)\n",
    "            x = self.transformer(x)\n",
    "            x = x.mean(dim=1)\n",
    "            return F.log_softmax(self.fc(x), dim=1)\n",
    "    \n",
    "    model_trans = TransformerDetector(n_seq_features)\n",
    "    optimizer_trans = torch.optim.Adam(model_trans.parameters(), lr=0.001)\n",
    "    \n",
    "    print('\ud83d\ude80 Training Transformer (20 epochs)...')\n",
    "    for epoch in range(20):\n",
    "        model_trans.train()\n",
    "        for seqs, labels in train_loader:\n",
    "            optimizer_trans.zero_grad()\n",
    "            loss = nn.NLLLoss()(model_trans(seqs), labels)\n",
    "            loss.backward()\n",
    "            optimizer_trans.step()\n",
    "        if (epoch + 1) % 5 == 0:\n",
    "            print(f'Epoch {epoch+1}')\n",
    "    \n",
    "    model_trans.eval()\n",
    "    trans_correct = trans_total = 0\n",
    "    with torch.no_grad():\n",
    "        for seqs, labels in test_loader:\n",
    "            trans_correct += (model_trans(seqs).argmax(dim=1) == labels).sum().item()\n",
    "            trans_total += labels.size(0)\n",
    "    trans_test_acc = trans_correct / trans_total\n",
    "    print(f'\\n\u2705 Transformer Test Accuracy: {trans_test_acc:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5\ufe0f\u20e3 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE and TORCH_GEO_AVAILABLE:\n",
    "    results = pd.DataFrame({\n",
    "        'Model': ['GNN', 'LSTM', 'Transformer'],\n",
    "        'Accuracy': [test_acc.item(), lstm_test_acc, trans_test_acc],\n",
    "        'Best For': ['Networks', 'Sequences', 'Long-range']\n",
    "    })\n",
    "    print('\\n' + '='*70)\n",
    "    print('\ud83c\udfc6 MODEL COMPARISON')\n",
    "    print('='*70)\n",
    "    print(results.to_string(index=False))\n",
    "    print('='*70)\n",
    "    \n",
    "    plt.figure(figsize=(12, 7))\n",
    "    colors = ['#3498db', '#e74c3c', '#2ecc71']\n",
    "    bars = plt.bar(results['Model'], results['Accuracy'], color=colors, alpha=0.8)\n",
    "    for bar in bars:\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., bar.get_height(),\n",
    "                f'{bar.get_height():.4f}', ha='center', va='bottom', fontsize=14, fontweight='bold')\n",
    "    plt.title('\ud83e\udde0 Model Performance', fontsize=16, fontweight='bold')\n",
    "    plt.ylabel('Test Accuracy', fontsize=14)\n",
    "    plt.ylim(0, 1.1)\n",
    "    plt.grid(True, alpha=0.3, axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6\ufe0f\u20e3 Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if TORCH_AVAILABLE:\n",
    "    import os\n",
    "    os.makedirs('../models', exist_ok=True)\n",
    "    torch.save(model_lstm.state_dict(), '../models/lstm_detector.pth')\n",
    "    torch.save(model_trans.state_dict(), '../models/transformer_detector.pth')\n",
    "    if TORCH_GEO_AVAILABLE:\n",
    "        torch.save(model_gnn.state_dict(), '../models/gnn_detector.pth')\n",
    "    print('\ud83d\udcbe Models saved!')\n",
    "    print('\\n\ud83d\ude80 DEPLOYMENT CHECKLIST:')\n",
    "    print('  1. \u2705 Export to ONNX')\n",
    "    print('  2. \u2705 Quantize models')\n",
    "    print('  3. \u2705 Deploy with FastAPI')\n",
    "    print('  4. \u2705 Monitor latency')\n",
    "    print('  5. \u2705 A/B testing')\n",
    "    print('  6. \u2705 Continuous retraining')\n",
    "    print('  7. \u2705 Explain with SHAP')\n",
    "    print('\\n\u2705 NEXUS AI Deep Learning Complete! \ud83c\udf89')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}