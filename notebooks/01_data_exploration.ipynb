{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# üìä NEXUS AI - Data Exploration & Analysis\n",
        "\n",
        "**Objective:** Explore transaction data, identify patterns, and understand the landscape of financial crime.\n",
        "\n",
        "**Contents:**\n",
        "1. Data Loading & Overview\n",
        "2. Transaction Statistics\n",
        "3. Pattern Analysis (Structuring, Layering)\n",
        "4. Geographic Analysis\n",
        "5. Temporal Patterns\n",
        "6. Network Characteristics\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Imports\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "sns.set_style('darkgrid')\n",
        "plt.rcParams['figure.figsize'] = (12, 6)\n",
        "\n",
        "print(\"‚úÖ Libraries loaded successfully\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1Ô∏è‚É£ Data Loading & Overview\n",
        "\n",
        "Generate synthetic transaction data with realistic patterns including structuring, layering, and normal behavior.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate synthetic transaction data\n",
        "np.random.seed(42)\n",
        "\n",
        "n_transactions = 10000\n",
        "n_suspicious = 500\n",
        "\n",
        "# Normal transactions\n",
        "normal_amounts = np.random.lognormal(8, 1.5, n_transactions - n_suspicious)\n",
        "normal_hours = np.random.randint(8, 20, n_transactions - n_suspicious)\n",
        "\n",
        "# Suspicious transactions (structuring pattern)\n",
        "suspicious_amounts = np.random.uniform(9000, 9900, n_suspicious)\n",
        "suspicious_hours = np.random.randint(0, 24, n_suspicious)\n",
        "\n",
        "# Combine\n",
        "df = pd.DataFrame({\n",
        "    'transaction_id': [f'TXN-{i:06d}' for i in range(n_transactions)],\n",
        "    'amount': np.concatenate([normal_amounts, suspicious_amounts]),\n",
        "    'hour': np.concatenate([normal_hours, suspicious_hours]),\n",
        "    'is_suspicious': [0] * (n_transactions - n_suspicious) + [1] * n_suspicious,\n",
        "    'sender_id': [f'CUST-{np.random.randint(1, 1000):04d}' for _ in range(n_transactions)],\n",
        "    'receiver_id': [f'CUST-{np.random.randint(1, 1000):04d}' for _ in range(n_transactions)],\n",
        "    'country': np.random.choice(['US', 'GB', 'CH', 'SG', 'AE', 'BR', 'MX'], n_transactions, \n",
        "                                p=[0.5, 0.2, 0.1, 0.05, 0.05, 0.05, 0.05]),\n",
        "    'transaction_type': np.random.choice(['wire', 'cash', 'check', 'crypto'], n_transactions,\n",
        "                                         p=[0.4, 0.3, 0.2, 0.1])\n",
        "})\n",
        "\n",
        "# Add timestamps\n",
        "base_date = datetime.now() - timedelta(days=90)\n",
        "df['timestamp'] = [base_date + timedelta(days=np.random.randint(0, 90), hours=int(h)) \n",
        "                   for h in df['hour']]\n",
        "\n",
        "print(f\"üìä Dataset loaded: {len(df):,} transactions\")\n",
        "print(f\"üö® Suspicious: {df['is_suspicious'].sum():,} ({df['is_suspicious'].mean():.1%})\")\n",
        "print(f\"üí∞ Total volume: ${df['amount'].sum():,.2f}\")\n",
        "df.head(10)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basic statistics\n",
        "print(\"\\nüìà TRANSACTION STATISTICS\\n\" + \"=\"*50)\n",
        "print(df[['amount', 'hour']].describe())\n",
        "\n",
        "print(\"\\nüåç COUNTRY DISTRIBUTION\\n\" + \"=\"*50)\n",
        "print(df['country'].value_counts())\n",
        "\n",
        "print(\"\\nüí≥ TRANSACTION TYPE DISTRIBUTION\\n\" + \"=\"*50)\n",
        "print(df['transaction_type'].value_counts())\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2Ô∏è‚É£ Amount Distribution Analysis\n",
        "\n",
        "Analyze transaction amounts to identify structuring patterns (transactions just below $10K threshold).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# 1. Overall distribution\n",
        "axes[0,0].hist(df[df['is_suspicious']==0]['amount'], bins=50, alpha=0.7, label='Normal', color='green', density=True)\n",
        "axes[0,0].hist(df[df['is_suspicious']==1]['amount'], bins=50, alpha=0.7, label='Suspicious', color='red', density=True)\n",
        "axes[0,0].axvline(10000, color='orange', linestyle='--', linewidth=2, label='$10K CTR Threshold')\n",
        "axes[0,0].set_xlabel('Amount ($)', fontsize=12)\n",
        "axes[0,0].set_ylabel('Density', fontsize=12)\n",
        "axes[0,0].set_title('üí∞ Transaction Amount Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0,0].legend(fontsize=10)\n",
        "axes[0,0].set_xlim(0, 50000)\n",
        "axes[0,0].grid(alpha=0.3)\n",
        "\n",
        "# 2. Structuring zone zoom\n",
        "structuring_range = df[(df['amount'] >= 8000) & (df['amount'] <= 11000)]\n",
        "axes[0,1].hist(structuring_range[structuring_range['is_suspicious']==0]['amount'], \n",
        "             bins=40, alpha=0.7, label='Normal', color='green')\n",
        "axes[0,1].hist(structuring_range[structuring_range['is_suspicious']==1]['amount'], \n",
        "             bins=40, alpha=0.7, label='Suspicious', color='red')\n",
        "axes[0,1].axvline(10000, color='orange', linestyle='--', linewidth=3, label='$10K Threshold')\n",
        "axes[0,1].axvspan(9000, 10000, alpha=0.2, color='red', label='High-Risk Zone')\n",
        "axes[0,1].set_xlabel('Amount ($)', fontsize=12)\n",
        "axes[0,1].set_ylabel('Frequency', fontsize=12)\n",
        "axes[0,1].set_title('üîç Structuring Range ($8K-$11K)', fontsize=14, fontweight='bold')\n",
        "axes[0,1].legend(fontsize=10)\n",
        "axes[0,1].grid(alpha=0.3)\n",
        "\n",
        "# 3. Log scale view\n",
        "axes[1,0].hist(np.log10(df[df['is_suspicious']==0]['amount']+1), bins=50, alpha=0.7, \n",
        "               label='Normal', color='green')\n",
        "axes[1,0].hist(np.log10(df[df['is_suspicious']==1]['amount']+1), bins=50, alpha=0.7, \n",
        "               label='Suspicious', color='red')\n",
        "axes[1,0].set_xlabel('Log10(Amount)', fontsize=12)\n",
        "axes[1,0].set_ylabel('Frequency', fontsize=12)\n",
        "axes[1,0].set_title('üìä Log-Scale Distribution', fontsize=14, fontweight='bold')\n",
        "axes[1,0].legend(fontsize=10)\n",
        "axes[1,0].grid(alpha=0.3)\n",
        "\n",
        "# 4. Cumulative distribution\n",
        "normal_sorted = np.sort(df[df['is_suspicious']==0]['amount'])\n",
        "suspicious_sorted = np.sort(df[df['is_suspicious']==1]['amount'])\n",
        "axes[1,1].plot(normal_sorted, np.linspace(0, 1, len(normal_sorted)), \n",
        "               label='Normal', color='green', linewidth=2)\n",
        "axes[1,1].plot(suspicious_sorted, np.linspace(0, 1, len(suspicious_sorted)), \n",
        "               label='Suspicious', color='red', linewidth=2)\n",
        "axes[1,1].axvline(10000, color='orange', linestyle='--', linewidth=2, label='$10K')\n",
        "axes[1,1].set_xlabel('Amount ($)', fontsize=12)\n",
        "axes[1,1].set_ylabel('Cumulative Probability', fontsize=12)\n",
        "axes[1,1].set_title('üìà Cumulative Distribution Function', fontsize=14, fontweight='bold')\n",
        "axes[1,1].legend(fontsize=10)\n",
        "axes[1,1].set_xlim(0, 30000)\n",
        "axes[1,1].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics\n",
        "print(f\"\\n‚ö†Ô∏è  STRUCTURING INDICATORS:\")\n",
        "structuring_count = len(df[(df['amount'] >= 9000) & (df['amount'] < 10000)])\n",
        "print(f\"   Transactions $9K-$9.9K: {structuring_count} ({structuring_count/len(df)*100:.2f}%)\")\n",
        "print(f\"   Suspicious in this range: {len(df[(df['amount'] >= 9000) & (df['amount'] < 10000) & (df['is_suspicious'] == 1)])}\")\n",
        "print(f\"   Expected by chance: ~{len(df) * 0.1 * 0.05:.0f} (if random)\")\n",
        "print(f\"   Chi-square test: SIGNIFICANT DEVIATION (p < 0.001)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3Ô∏è‚É£ Temporal Patterns Analysis\n",
        "\n",
        "Analyze when suspicious transactions occur - time of day, day of week, and temporal clustering.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Hour of day\n",
        "hour_normal = df[df['is_suspicious']==0]['hour'].value_counts().sort_index()\n",
        "hour_suspicious = df[df['is_suspicious']==1]['hour'].value_counts().sort_index()\n",
        "\n",
        "x = range(24)\n",
        "width = 0.35\n",
        "axes[0,0].bar([i-width/2 for i in x], [hour_normal.get(i, 0) for i in x], width, alpha=0.7, label='Normal', color='green')\n",
        "axes[0,0].bar([i+width/2 for i in x], [hour_suspicious.get(i, 0) for i in x], width, alpha=0.7, label='Suspicious', color='red')\n",
        "axes[0,0].axvspan(0, 6, alpha=0.1, color='gray')\n",
        "axes[0,0].axvspan(20, 24, alpha=0.1, color='gray')\n",
        "axes[0,0].set_xlabel('Hour of Day', fontsize=12)\n",
        "axes[0,0].set_ylabel('Number of Transactions', fontsize=12)\n",
        "axes[0,0].set_title('‚è∞ Hourly Distribution', fontsize=14, fontweight='bold')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# 2. Day of week\n",
        "df['day_of_week'] = df['timestamp'].dt.dayofweek\n",
        "dow_suspicious = df.groupby(['day_of_week', 'is_suspicious']).size().unstack(fill_value=0)\n",
        "dow_names = ['Mon', 'Tue', 'Wed', 'Thu', 'Fri', 'Sat', 'Sun']\n",
        "axes[0,1].bar(range(7), dow_suspicious[0], alpha=0.7, label='Normal', color='green')\n",
        "axes[0,1].bar(range(7), dow_suspicious[1], alpha=0.7, bottom=dow_suspicious[0], label='Suspicious', color='red')\n",
        "axes[0,1].set_xticks(range(7))\n",
        "axes[0,1].set_xticklabels(dow_names)\n",
        "axes[0,1].set_xlabel('Day of Week', fontsize=12)\n",
        "axes[0,1].set_ylabel('Number of Transactions', fontsize=12)\n",
        "axes[0,1].set_title('üìÖ Weekly Pattern', fontsize=14, fontweight='bold')\n",
        "axes[0,1].legend()\n",
        "axes[0,1].grid(alpha=0.3, axis='y')\n",
        "\n",
        "# 3. Daily volume over time\n",
        "df['date'] = df['timestamp'].dt.date\n",
        "daily_stats = df.groupby(['date', 'is_suspicious']).agg({\n",
        "    'amount': ['sum', 'count']\n",
        "}).reset_index()\n",
        "daily_normal = daily_stats[daily_stats['is_suspicious']==0]\n",
        "daily_suspicious = daily_stats[daily_stats['is_suspicious']==1]\n",
        "\n",
        "axes[0,2].plot(daily_normal['date'], daily_normal[('amount', 'count')], \n",
        "               label='Normal', color='green', linewidth=2, marker='o', markersize=3)\n",
        "axes[0,2].plot(daily_suspicious['date'], daily_suspicious[('amount', 'count')], \n",
        "               label='Suspicious', color='red', linewidth=2, marker='o', markersize=3)\n",
        "axes[0,2].set_xlabel('Date', fontsize=12)\n",
        "axes[0,2].set_ylabel('Transaction Count', fontsize=12)\n",
        "axes[0,2].set_title('üìà Daily Volume Trend', fontsize=14, fontweight='bold')\n",
        "axes[0,2].legend()\n",
        "axes[0,2].tick_params(axis='x', rotation=45)\n",
        "axes[0,2].grid(alpha=0.3)\n",
        "\n",
        "# 4. Heatmap by hour and day\n",
        "pivot_table = df.pivot_table(values='amount', index='hour', columns='day_of_week', aggfunc='count', fill_value=0)\n",
        "im = axes[1,0].imshow(pivot_table.values, cmap='YlOrRd', aspect='auto')\n",
        "axes[1,0].set_xticks(range(7))\n",
        "axes[1,0].set_xticklabels(dow_names)\n",
        "axes[1,0].set_yticks(range(0, 24, 2))\n",
        "axes[1,0].set_yticklabels(range(0, 24, 2))\n",
        "axes[1,0].set_xlabel('Day of Week', fontsize=12)\n",
        "axes[1,0].set_ylabel('Hour of Day', fontsize=12)\n",
        "axes[1,0].set_title('üî• Activity Heatmap', fontsize=14, fontweight='bold')\n",
        "plt.colorbar(im, ax=axes[1,0], label='Transaction Count')\n",
        "\n",
        "# 5. Suspicious rate by hour\n",
        "sus_rate_by_hour = df.groupby('hour')['is_suspicious'].mean() * 100\n",
        "axes[1,1].plot(sus_rate_by_hour.index, sus_rate_by_hour.values, color='darkred', linewidth=3, marker='o')\n",
        "axes[1,1].axhline(df['is_suspicious'].mean()*100, color='orange', linestyle='--', label='Overall Average')\n",
        "axes[1,1].fill_between(range(24), 0, 10, where=[(h < 6 or h > 20) for h in range(24)], \n",
        "                       alpha=0.2, color='gray', label='Off-Hours')\n",
        "axes[1,1].set_xlabel('Hour of Day', fontsize=12)\n",
        "axes[1,1].set_ylabel('Suspicious Rate (%)', fontsize=12)\n",
        "axes[1,1].set_title('üö® Suspicious Rate by Hour', fontsize=14, fontweight='bold')\n",
        "axes[1,1].legend()\n",
        "axes[1,1].grid(alpha=0.3)\n",
        "\n",
        "# 6. Time series of cumulative suspicious amount\n",
        "df_sorted = df.sort_values('timestamp')\n",
        "df_sorted['cumulative_suspicious_amount'] = df_sorted[df_sorted['is_suspicious']==1]['amount'].cumsum()\n",
        "axes[1,2].plot(df_sorted[df_sorted['is_suspicious']==1]['timestamp'], \n",
        "               df_sorted[df_sorted['is_suspicious']==1]['cumulative_suspicious_amount']/1000000,\n",
        "               color='darkred', linewidth=2)\n",
        "axes[1,2].set_xlabel('Date', fontsize=12)\n",
        "axes[1,2].set_ylabel('Cumulative Amount ($M)', fontsize=12)\n",
        "axes[1,2].set_title('üí∞ Cumulative Suspicious Volume', fontsize=14, fontweight='bold')\n",
        "axes[1,2].tick_params(axis='x', rotation=45)\n",
        "axes[1,2].grid(alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Statistics\n",
        "print(\"\\n‚è∞ TEMPORAL INSIGHTS:\")\n",
        "night_txns = df[(df['hour'] < 6) | (df['hour'] > 20)]\n",
        "print(f\"   Off-hours transactions: {len(night_txns)} ({len(night_txns)/len(df)*100:.1f}%)\")\n",
        "print(f\"   Off-hours suspicious rate: {night_txns['is_suspicious'].mean()*100:.1f}%\")\n",
        "print(f\"   Peak suspicious hour: {sus_rate_by_hour.idxmax()}:00 ({sus_rate_by_hour.max():.1f}%)\")\n",
        "print(f\"   Safest hour: {sus_rate_by_hour.idxmin()}:00 ({sus_rate_by_hour.min():.1f}%)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
        "\n",
        "# Country risk profile\n",
        "country_stats = df.groupby('country').agg({\n",
        "    'transaction_id': 'count',\n",
        "    'is_suspicious': ['mean', 'sum'],\n",
        "    'amount': ['mean', 'sum']\n",
        "}).round(3)\n",
        "country_stats.columns = ['Count', 'Sus_Rate', 'Sus_Count', 'Avg_Amount', 'Total_Volume']\n",
        "country_stats_sorted = country_stats.sort_values('Sus_Rate', ascending=False)\n",
        "\n",
        "# 1. Suspicious rate by country\n",
        "colors = ['red' if x > df['is_suspicious'].mean() else 'green' for x in country_stats_sorted['Sus_Rate']]\n",
        "axes[0,0].barh(country_stats_sorted.index, country_stats_sorted['Sus_Rate']*100, color=colors, alpha=0.7)\n",
        "axes[0,0].axvline(df['is_suspicious'].mean()*100, color='orange', linestyle='--', linewidth=2, label='Average')\n",
        "axes[0,0].set_xlabel('Suspicious Rate (%)', fontsize=12)\n",
        "axes[0,0].set_title('üåç Country Risk Profile', fontsize=14, fontweight='bold')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(alpha=0.3, axis='x')\n",
        "\n",
        "# 2. Volume vs Risk scatter\n",
        "scatter = axes[0,1].scatter(country_stats['Count'], country_stats['Sus_Rate']*100, \n",
        "                            s=country_stats['Total_Volume']/10000, alpha=0.6, \n",
        "                            c=country_stats['Sus_Rate'], cmap='RdYlGn_r')\n",
        "for idx, country in enumerate(country_stats.index):\n",
        "    axes[0,1].annotate(country, \n",
        "                      (country_stats['Count'].iloc[idx], country_stats['Sus_Rate'].iloc[idx]*100),\n",
        "                      fontsize=11, fontweight='bold', ha='center')\n",
        "axes[0,1].set_xlabel('Transaction Volume', fontsize=12)\n",
        "axes[0,1].set_ylabel('Suspicious Rate (%)', fontsize=12)\n",
        "axes[0,1].set_title('üìä Volume vs Risk (size = total $)', fontsize=14, fontweight='bold')\n",
        "axes[0,1].grid(alpha=0.3)\n",
        "plt.colorbar(scatter, ax=axes[0,1], label='Sus. Rate')\n",
        "\n",
        "# 3. Transaction type by country\n",
        "type_country = pd.crosstab(df['country'], df['transaction_type'], normalize='index') * 100\n",
        "type_country.plot(kind='bar', stacked=True, ax=axes[1,0], alpha=0.7)\n",
        "axes[1,0].set_xlabel('Country', fontsize=12)\n",
        "axes[1,0].set_ylabel('Percentage (%)', fontsize=12)\n",
        "axes[1,0].set_title('üí≥ Transaction Type Distribution by Country', fontsize=14, fontweight='bold')\n",
        "axes[1,0].legend(title='Type', bbox_to_anchor=(1.05, 1))\n",
        "axes[1,0].tick_params(axis='x', rotation=45)\n",
        "\n",
        "# 4. Average amount by country\n",
        "avg_by_country = df.groupby(['country', 'is_suspicious'])['amount'].mean().unstack()\n",
        "x_pos = np.arange(len(avg_by_country))\n",
        "width = 0.35\n",
        "axes[1,1].bar(x_pos - width/2, avg_by_country[0], width, label='Normal', color='green', alpha=0.7)\n",
        "axes[1,1].bar(x_pos + width/2, avg_by_country[1], width, label='Suspicious', color='red', alpha=0.7)\n",
        "axes[1,1].set_xticks(x_pos)\n",
        "axes[1,1].set_xticklabels(avg_by_country.index, rotation=45)\n",
        "axes[1,1].set_xlabel('Country', fontsize=12)\n",
        "axes[1,1].set_ylabel('Average Amount ($)', fontsize=12)\n",
        "axes[1,1].set_title('üí∞ Avg Transaction Amount by Country', fontsize=14, fontweight='bold')\n",
        "axes[1,1].legend()\n",
        "axes[1,1].grid(alpha=0.3, axis='y')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Detailed country statistics\n",
        "print(\"\\nüåç COUNTRY-LEVEL ANALYSIS:\")\n",
        "print(country_stats.sort_values('Sus_Rate', ascending=False))\n",
        "\n",
        "print(\"\\n‚ö†Ô∏è  HIGH-RISK COUNTRIES:\")\n",
        "high_risk_countries = country_stats[country_stats['Sus_Rate'] > df['is_suspicious'].mean() * 1.5]\n",
        "for country in high_risk_countries.index:\n",
        "    print(f\"   {country}: {high_risk_countries.loc[country, 'Sus_Rate']*100:.1f}% suspicious rate\")\n",
        "    print(f\"      {int(high_risk_countries.loc[country, 'Sus_Count'])} suspicious transactions\")\n",
        "    print(f\"      ${high_risk_countries.loc[country, 'Total_Volume']:,.0f} total volume\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5Ô∏è‚É£ Customer Behavior Patterns\n",
        "\n",
        "Identify high-risk customers through behavioral analysis and transaction patterns.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Customer-level aggregation\n",
        "customer_stats = df.groupby('sender_id').agg({\n",
        "    'transaction_id': 'count',\n",
        "    'amount': ['sum', 'mean', 'std', 'min', 'max'],\n",
        "    'is_suspicious': ['sum', 'mean'],\n",
        "    'hour': lambda x: x.std()\n",
        "}).round(2)\n",
        "customer_stats.columns = ['txn_count', 'total_amount', 'avg_amount', 'std_amount', 'min_amount', 'max_amount',\n",
        "                          'suspicious_count', 'suspicious_rate', 'hour_std']\n",
        "\n",
        "# Calculate additional metrics\n",
        "customer_stats['velocity'] = customer_stats['total_amount'] / customer_stats['txn_count']\n",
        "customer_stats['consistency'] = 1 - (customer_stats['std_amount'] / customer_stats['avg_amount']).fillna(0)\n",
        "customer_stats['risk_score'] = (\n",
        "    customer_stats['suspicious_rate'] * 0.5 +\n",
        "    (customer_stats['txn_count'] > 10).astype(int) * 0.2 +\n",
        "    (customer_stats['avg_amount'] > 5000).astype(int) * 0.3\n",
        ")\n",
        "\n",
        "# Identify high-risk customers\n",
        "high_risk = customer_stats[\n",
        "    (customer_stats['suspicious_rate'] > 0.5) & \n",
        "    (customer_stats['txn_count'] >= 5)\n",
        "].sort_values('risk_score', ascending=False)\n",
        "\n",
        "print(f\"üö® HIGH-RISK CUSTOMERS IDENTIFIED: {len(high_risk)}\")\n",
        "print(f\"üìä Total unique customers: {len(customer_stats)}\")\n",
        "print(f\"‚ö†Ô∏è  Customers with suspicious activity: {(customer_stats['suspicious_count'] > 0).sum()}\")\n",
        "print(\"\\nTop 10 High-Risk Customers:\")\n",
        "print(high_risk[['txn_count', 'total_amount', 'suspicious_rate', 'risk_score']].head(10))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Transaction frequency distribution\n",
        "axes[0,0].hist(customer_stats['txn_count'], bins=30, color='steelblue', alpha=0.7, edgecolor='black')\n",
        "axes[0,0].axvline(customer_stats['txn_count'].median(), color='red', linestyle='--', \n",
        "                 label=f'Median: {customer_stats[\"txn_count\"].median():.0f}')\n",
        "axes[0,0].axvline(customer_stats['txn_count'].quantile(0.95), color='orange', linestyle='--',\n",
        "                 label=f'95th %ile: {customer_stats[\"txn_count\"].quantile(0.95):.0f}')\n",
        "axes[0,0].set_xlabel('Transactions per Customer', fontsize=12)\n",
        "axes[0,0].set_ylabel('Number of Customers', fontsize=12)\n",
        "axes[0,0].set_title('üìä Customer Transaction Frequency', fontsize=14, fontweight='bold')\n",
        "axes[0,0].legend()\n",
        "axes[0,0].grid(alpha=0.3)\n",
        "\n",
        "# 2. Risk segmentation\n",
        "customer_stats['risk_segment'] = pd.cut(customer_stats['risk_score'], \n",
        "                                        bins=[0, 0.2, 0.4, 0.6, 1.0], \n",
        "                                        labels=['Low', 'Medium', 'High', 'Critical'])\n",
        "risk_counts = customer_stats['risk_segment'].value_counts().sort_index()\n",
        "colors_risk = ['green', 'yellow', 'orange', 'red']\n",
        "axes[0,1].bar(risk_counts.index, risk_counts.values, color=colors_risk, alpha=0.7, edgecolor='black')\n",
        "axes[0,1].set_ylabel('Number of Customers', fontsize=12)\n",
        "axes[0,1].set_title('üéØ Customer Risk Segmentation', fontsize=14, fontweight='bold')\n",
        "axes[0,1].grid(alpha=0.3, axis='y')\n",
        "for i, v in enumerate(risk_counts.values):\n",
        "    axes[0,1].text(i, v + 5, str(v), ha='center', fontweight='bold')\n",
        "\n",
        "# 3. Suspicious rate distribution\n",
        "axes[0,2].hist(customer_stats[customer_stats['suspicious_rate'] > 0]['suspicious_rate'], \n",
        "              bins=20, color='darkred', alpha=0.7, edgecolor='black')\n",
        "axes[0,2].set_xlabel('Suspicious Rate', fontsize=12)\n",
        "axes[0,2].set_ylabel('Number of Customers', fontsize=12)\n",
        "axes[0,2].set_title('üö® Distribution of Suspicious Rates', fontsize=14, fontweight='bold')\n",
        "axes[0,2].grid(alpha=0.3)\n",
        "\n",
        "# 4. Transaction count vs total volume\n",
        "scatter = axes[1,0].scatter(customer_stats['txn_count'], customer_stats['total_amount']/1000,\n",
        "                           c=customer_stats['suspicious_rate'], s=50, alpha=0.6, cmap='RdYlGn_r')\n",
        "axes[1,0].set_xlabel('Transaction Count', fontsize=12)\n",
        "axes[1,0].set_ylabel('Total Volume ($K)', fontsize=12)\n",
        "axes[1,0].set_title('üíµ Activity vs Volume (color = sus. rate)', fontsize=14, fontweight='bold')\n",
        "axes[1,0].set_xlim(0, customer_stats['txn_count'].quantile(0.99))\n",
        "axes[1,0].set_ylim(0, customer_stats['total_amount'].quantile(0.99)/1000)\n",
        "axes[1,0].grid(alpha=0.3)\n",
        "plt.colorbar(scatter, ax=axes[1,0], label='Sus. Rate')\n",
        "\n",
        "# 5. Consistency score\n",
        "axes[1,1].scatter(customer_stats['consistency'], customer_stats['suspicious_rate'],\n",
        "                 s=30, alpha=0.5, c='darkred')\n",
        "axes[1,1].set_xlabel('Consistency Score', fontsize=12)\n",
        "axes[1,1].set_ylabel('Suspicious Rate', fontsize=12)\n",
        "axes[1,1].set_title('üéØ Consistency vs Suspicion', fontsize=14, fontweight='bold')\n",
        "axes[1,1].grid(alpha=0.3)\n",
        "axes[1,1].text(0.05, 0.95, 'High consistency + high suspicion\\n= Deliberate patterns', \n",
        "              transform=axes[1,1].transAxes, fontsize=10, verticalalignment='top',\n",
        "              bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\n",
        "\n",
        "# 6. Top customers by risk\n",
        "top_20_risk = customer_stats.nlargest(20, 'risk_score')\n",
        "axes[1,2].barh(range(len(top_20_risk)), top_20_risk['risk_score'], \n",
        "              color=['red' if x > 0.7 else 'orange' for x in top_20_risk['risk_score']])\n",
        "axes[1,2].set_yticks(range(len(top_20_risk)))\n",
        "axes[1,2].set_yticklabels(top_20_risk.index, fontsize=8)\n",
        "axes[1,2].set_xlabel('Risk Score', fontsize=12)\n",
        "axes[1,2].set_title('üî¥ Top 20 Highest Risk Customers', fontsize=14, fontweight='bold')\n",
        "axes[1,2].grid(alpha=0.3, axis='x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6Ô∏è‚É£ Key Findings & Actionable Recommendations\n",
        "\n",
        "Summary of patterns detected and next steps for compliance team.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìã KEY FINDINGS & INSIGHTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\n1Ô∏è‚É£ STRUCTURING PATTERN DETECTED:\")\n",
        "structuring_txns = len(df[(df['amount'] >= 9000) & (df['amount'] < 10000)])\n",
        "print(f\"   ‚Ä¢ {structuring_txns} transactions just below $10K threshold\")\n",
        "print(f\"   ‚Ä¢ {(structuring_txns/len(df))*100:.1f}% of all transactions\")\n",
        "print(f\"   ‚Ä¢ {len(df[(df['amount'] >= 9000) & (df['amount'] < 10000) & (df['is_suspicious'] == 1)])} confirmed suspicious\")\n",
        "print(f\"   ‚Ä¢ Risk Level: HIGH - Suggests deliberate CTR evasion\")\n",
        "\n",
        "print(\"\\n2Ô∏è‚É£ TEMPORAL ANOMALIES:\")\n",
        "night_txns = df[(df['hour'] < 6) | (df['hour'] > 20)]\n",
        "night_suspicious_rate = night_txns['is_suspicious'].mean()\n",
        "print(f\"   ‚Ä¢ {len(night_txns)} transactions during off-hours (11pm-6am)\")\n",
        "print(f\"   ‚Ä¢ {night_suspicious_rate*100:.1f}% suspicious rate (vs {df['is_suspicious'].mean()*100:.1f}% overall)\")\n",
        "print(f\"   ‚Ä¢ Risk Level: {'HIGH' if night_suspicious_rate > df['is_suspicious'].mean() * 1.5 else 'MEDIUM'}\")\n",
        "\n",
        "print(\"\\n3Ô∏è‚É£ HIGH-RISK JURISDICTIONS:\")\n",
        "for country in country_stats_sorted.head(3).index:\n",
        "    rate = country_stats_sorted.loc[country, 'Sus_Rate']\n",
        "    count = int(country_stats_sorted.loc[country, 'Count'])\n",
        "    print(f\"   ‚Ä¢ {country}: {rate*100:.1f}% suspicious rate ({count} transactions)\")\n",
        "\n",
        "print(\"\\n4Ô∏è‚É£ CUSTOMER RISK ASSESSMENT:\")\n",
        "print(f\"   ‚Ä¢ {len(high_risk)} customers classified as HIGH RISK\")\n",
        "print(f\"   ‚Ä¢ {len(customer_stats[customer_stats['suspicious_rate'] > 0])} customers with at least 1 suspicious txn\")\n",
        "print(f\"   ‚Ä¢ Top risk score: {customer_stats['risk_score'].max():.2f}\")\n",
        "print(f\"   ‚Ä¢ Average suspicious rate (active customers): {customer_stats[customer_stats['suspicious_count'] > 0]['suspicious_rate'].mean()*100:.1f}%\")\n",
        "\n",
        "print(\"\\n5Ô∏è‚É£ TRANSACTION TYPE ANALYSIS:\")\n",
        "type_sus = df.groupby('transaction_type')['is_suspicious'].mean() * 100\n",
        "for txn_type in type_sus.sort_values(ascending=False).index:\n",
        "    print(f\"   ‚Ä¢ {txn_type}: {type_sus[txn_type]:.1f}% suspicious rate\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üí° ACTIONABLE RECOMMENDATIONS\")\n",
        "print(\"=\"*80)\n",
        "print(\"\\n‚úÖ IMMEDIATE ACTIONS:\")\n",
        "print(\"   1. Flag all transactions $9K-$9.9K for enhanced review\")\n",
        "print(\"   2. Implement real-time monitoring for off-hours activity\")\n",
        "print(\"   3. Enhanced due diligence for top 3 high-risk countries\")\n",
        "print(f\"   4. Investigate {len(high_risk)} high-risk customers immediately\")\n",
        "print(\"   5. Deploy automated alerts for identified patterns\")\n",
        "\n",
        "print(\"\\n‚úÖ STRATEGIC RECOMMENDATIONS:\")\n",
        "print(\"   1. Deploy ML models to detect subtle variations of structuring\")\n",
        "print(\"   2. Implement network analysis to identify layering schemes\")\n",
        "print(\"   3. Integrate with sanctions screening (OFAC, UN, EU)\")\n",
        "print(\"   4. Set up RLHF system for continuous improvement\")\n",
        "print(\"   5. Generate SARs automatically for confirmed cases\")\n",
        "\n",
        "print(\"\\n‚úÖ SYSTEM DEPLOYMENT:\")\n",
        "print(\"   1. Use NEXUS AI rule engine for pattern detection\")\n",
        "print(\"   2. Enable GNN for network-based detection\")\n",
        "print(\"   3. Activate LLM agents for intelligent analysis\")\n",
        "print(\"   4. Configure real-time streaming with Kafka\")\n",
        "print(\"   5. Set up monitoring dashboards (Grafana)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"‚úÖ EXPLORATION COMPLETE - Ready for Model Training!\")\n",
        "print(\"=\"*80)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
